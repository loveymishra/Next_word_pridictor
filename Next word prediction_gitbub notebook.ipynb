{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next word predictor using LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collecting and preprocessing phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have downloaded 17 subltitle files of friends tv show and converted it into text files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below i have concatinated all 17 text file in single corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters in Corpus: 275359\n"
     ]
    }
   ],
   "source": [
    "corpus = \"\"\n",
    "\n",
    "# Loop through all files from f1.txt to f17.txt\n",
    "for i in range(1, 18):  # 1 to 17\n",
    "    file_name = f\"C:\\\\Users\\\\PC\\\\Desktop\\\\sub\\\\f{i}.txt\"  # Format file names dynamically\n",
    "    try:\n",
    "        with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "            corpus += f.read() + \" \"  # Add space between files\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_name} not found. Skipping.\")\n",
    "\n",
    "# Print corpus length to check\n",
    "print(\"Total Characters in Corpus:\", len(corpus))\n",
    "\n",
    "# Save the combined text (Optional)\n",
    "with open(\"combined_corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(corpus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saved the cleaned text in .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned text saved as 'cleaned_corpus.txt'\n"
     ]
    }
   ],
   "source": [
    "# Saved the cleaned text to a file\n",
    "with open(\"C:\\\\Users\\\\PC\\\\Desktop\\\\cleaned_corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(corpus)\n",
    "\n",
    "print(\"Cleaned text saved as 'cleaned_corpus.txt'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing and cleaning the data below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 75,
     "status": "ok",
     "timestamp": 1740462074806,
     "user": {
      "displayName": "Pankaj Mishra",
      "userId": "00940582812025533532"
     },
     "user_tz": -330
    },
    "id": "p-vhjDreJeBI"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Function to remove emojis using regex\n",
    "def remove_emojis(text):\n",
    "    return re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "\n",
    "# Function to process the text file\n",
    "def process_text_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Remove emojis and lines with less than 2 words\n",
    "    cleaned_lines = [remove_emojis(line.strip()) for line in lines if len(line.split()) >= 2]\n",
    "\n",
    "    # Count occurrences of each line\n",
    "    line_counts = Counter(cleaned_lines)\n",
    "\n",
    "    # Filter out lines that appear more than 4 times\n",
    "    final_lines = [line for line in cleaned_lines if line_counts[line] <= 4]\n",
    "\n",
    "#     # Join all lines into one paragraph\n",
    "#     paragraph = ' '.join(final_lines)\n",
    "\n",
    "    return final_lines\n",
    "\n",
    "# Example usage\n",
    "file_path = \"/content/cleaned_corpus.txt\"  # Replace with your file path\n",
    "result = process_text_file(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converted the it into list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1740462089591,
     "user": {
      "displayName": "Pankaj Mishra",
      "userId": "00940582812025533532"
     },
     "user_tz": -330
    },
    "id": "u31rYDM9koq4"
   },
   "outputs": [],
   "source": [
    "data=[]\n",
    "for i in result:\n",
    "    data.append(i+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "\n",
    "# Step 1: Preprocess the data\n",
    "# Lowercase and clean the data\n",
    "cleaned_data = [line.strip().lower() for line in data]\n",
    "\n",
    "# Combine all lines into a single text\n",
    "full_text = \" \".join(cleaned_data)\n",
    "\n",
    "# Step 2: Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([full_text])\n",
    "word_index = tokenizer.word_index\n",
    "total_words = len(word_index) + 1  # Include one for padding index\n",
    "\n",
    "# Convert text into sequences of tokens\n",
    "input_sequences = []\n",
    "for line in cleaned_data:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# Step 3: Pad sequences and create input-output pairs\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n",
    "\n",
    "# Split into input (X) and output (y)\n",
    "X = input_sequences[:, :-1]\n",
    "y = input_sequences[:, -1]\n",
    "y = to_categorical(y, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "executionInfo": {
     "elapsed": 5272,
     "status": "ok",
     "timestamp": 1740462104903,
     "user": {
      "displayName": "Pankaj Mishra",
      "userId": "00940582812025533532"
     },
     "user_tz": -330
    },
    "id": "Vo6TFXXQn-O8",
    "outputId": "d564c9c3-e9f5-46d0-e976-a24ffe265294"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 4: Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_len - 1))\n",
    "model.add(LSTM(150, return_sequences=True))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1740462114470,
     "user": {
      "displayName": "Pankaj Mishra",
      "userId": "00940582812025533532"
     },
     "user_tz": -330
    },
    "id": "08ptT_UWn-v2",
    "outputId": "ea65b805-c2fa-4f65-cf56-9f0c9ba3da3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sequence_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING PHASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 498691,
     "status": "ok",
     "timestamp": 1740462623400,
     "user": {
      "displayName": "Pankaj Mishra",
      "userId": "00940582812025533532"
     },
     "user_tz": -330
    },
    "id": "I1en3R7hn-yh",
    "outputId": "354d1065-a4f3-41ab-9749-2384a3c0664c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1241/1241 - 14s - 11ms/step - accuracy: 0.0408 - loss: 6.3161\n",
      "Epoch 2/50\n",
      "1241/1241 - 18s - 15ms/step - accuracy: 0.0634 - loss: 5.7810\n",
      "Epoch 3/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.0924 - loss: 5.4311\n",
      "Epoch 4/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.1100 - loss: 5.1737\n",
      "Epoch 5/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.1229 - loss: 4.9689\n",
      "Epoch 6/50\n",
      "1241/1241 - 8s - 7ms/step - accuracy: 0.1344 - loss: 4.7904\n",
      "Epoch 7/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.1455 - loss: 4.6278\n",
      "Epoch 8/50\n",
      "1241/1241 - 8s - 7ms/step - accuracy: 0.1526 - loss: 4.4820\n",
      "Epoch 9/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.1597 - loss: 4.3459\n",
      "Epoch 10/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.1685 - loss: 4.2177\n",
      "Epoch 11/50\n",
      "1241/1241 - 8s - 7ms/step - accuracy: 0.1752 - loss: 4.0966\n",
      "Epoch 12/50\n",
      "1241/1241 - 8s - 7ms/step - accuracy: 0.1833 - loss: 3.9829\n",
      "Epoch 13/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.1930 - loss: 3.8748\n",
      "Epoch 14/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.2053 - loss: 3.7769\n",
      "Epoch 15/50\n",
      "1241/1241 - 8s - 7ms/step - accuracy: 0.2158 - loss: 3.6826\n",
      "Epoch 16/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.2310 - loss: 3.5956\n",
      "Epoch 17/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.2389 - loss: 3.5145\n",
      "Epoch 18/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.2505 - loss: 3.4361\n",
      "Epoch 19/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.2620 - loss: 3.3614\n",
      "Epoch 20/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.2727 - loss: 3.2897\n",
      "Epoch 21/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.2848 - loss: 3.2254\n",
      "Epoch 22/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.2959 - loss: 3.1585\n",
      "Epoch 23/50\n",
      "1241/1241 - 11s - 9ms/step - accuracy: 0.3054 - loss: 3.0964\n",
      "Epoch 24/50\n",
      "1241/1241 - 8s - 7ms/step - accuracy: 0.3141 - loss: 3.0368\n",
      "Epoch 25/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.3278 - loss: 2.9767\n",
      "Epoch 26/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.3364 - loss: 2.9232\n",
      "Epoch 27/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.3494 - loss: 2.8673\n",
      "Epoch 28/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.3572 - loss: 2.8144\n",
      "Epoch 29/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.3665 - loss: 2.7623\n",
      "Epoch 30/50\n",
      "1241/1241 - 11s - 9ms/step - accuracy: 0.3763 - loss: 2.7162\n",
      "Epoch 31/50\n",
      "1241/1241 - 8s - 7ms/step - accuracy: 0.3874 - loss: 2.6665\n",
      "Epoch 32/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.3946 - loss: 2.6196\n",
      "Epoch 33/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.4049 - loss: 2.5742\n",
      "Epoch 34/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.4123 - loss: 2.5311\n",
      "Epoch 35/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.4222 - loss: 2.4870\n",
      "Epoch 36/50\n",
      "1241/1241 - 11s - 9ms/step - accuracy: 0.4300 - loss: 2.4466\n",
      "Epoch 37/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.4410 - loss: 2.4050\n",
      "Epoch 38/50\n",
      "1241/1241 - 8s - 7ms/step - accuracy: 0.4461 - loss: 2.3657\n",
      "Epoch 39/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.4572 - loss: 2.3254\n",
      "Epoch 40/50\n",
      "1241/1241 - 8s - 6ms/step - accuracy: 0.4626 - loss: 2.2913\n",
      "Epoch 41/50\n",
      "1241/1241 - 11s - 9ms/step - accuracy: 0.4717 - loss: 2.2505\n",
      "Epoch 42/50\n",
      "1241/1241 - 11s - 9ms/step - accuracy: 0.4781 - loss: 2.2166\n",
      "Epoch 43/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.4854 - loss: 2.1819\n",
      "Epoch 44/50\n",
      "1241/1241 - 8s - 7ms/step - accuracy: 0.4935 - loss: 2.1457\n",
      "Epoch 45/50\n",
      "1241/1241 - 8s - 6ms/step - accuracy: 0.4994 - loss: 2.1143\n",
      "Epoch 46/50\n",
      "1241/1241 - 8s - 7ms/step - accuracy: 0.5078 - loss: 2.0820\n",
      "Epoch 47/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.5156 - loss: 2.0511\n",
      "Epoch 48/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.5207 - loss: 2.0197\n",
      "Epoch 49/50\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.5279 - loss: 1.9906\n",
      "Epoch 50/50\n",
      "1241/1241 - 8s - 7ms/step - accuracy: 0.5372 - loss: 1.9622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7ca903343010>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Train the model\n",
    "model.fit(X, y, epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 394906,
     "status": "ok",
     "timestamp": 1740463279988,
     "user": {
      "displayName": "Pankaj Mishra",
      "userId": "00940582812025533532"
     },
     "user_tz": -330
    },
    "id": "Hqs1uaOCn-1k",
    "outputId": "8381f419-6941-4032-f2fc-054050e9899b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1241/1241 - 8s - 6ms/step - accuracy: 0.5419 - loss: 1.9343\n",
      "Epoch 2/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.5473 - loss: 1.9062\n",
      "Epoch 3/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.5561 - loss: 1.8794\n",
      "Epoch 4/40\n",
      "1241/1241 - 8s - 7ms/step - accuracy: 0.5613 - loss: 1.8546\n",
      "Epoch 5/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.5640 - loss: 1.8309\n",
      "Epoch 6/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.5683 - loss: 1.8074\n",
      "Epoch 7/40\n",
      "1241/1241 - 8s - 7ms/step - accuracy: 0.5757 - loss: 1.7861\n",
      "Epoch 8/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.5809 - loss: 1.7617\n",
      "Epoch 9/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.5845 - loss: 1.7419\n",
      "Epoch 10/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.5908 - loss: 1.7197\n",
      "Epoch 11/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.5945 - loss: 1.7002\n",
      "Epoch 12/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.5990 - loss: 1.6794\n",
      "Epoch 13/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6019 - loss: 1.6630\n",
      "Epoch 14/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6060 - loss: 1.6430\n",
      "Epoch 15/40\n",
      "1241/1241 - 11s - 9ms/step - accuracy: 0.6098 - loss: 1.6248\n",
      "Epoch 16/40\n",
      "1241/1241 - 8s - 7ms/step - accuracy: 0.6130 - loss: 1.6090\n",
      "Epoch 17/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6177 - loss: 1.5920\n",
      "Epoch 18/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6189 - loss: 1.5758\n",
      "Epoch 19/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6236 - loss: 1.5609\n",
      "Epoch 20/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6267 - loss: 1.5452\n",
      "Epoch 21/40\n",
      "1241/1241 - 11s - 9ms/step - accuracy: 0.6286 - loss: 1.5314\n",
      "Epoch 22/40\n",
      "1241/1241 - 8s - 7ms/step - accuracy: 0.6322 - loss: 1.5167\n",
      "Epoch 23/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6329 - loss: 1.5062\n",
      "Epoch 24/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6348 - loss: 1.4914\n",
      "Epoch 25/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6380 - loss: 1.4796\n",
      "Epoch 26/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6413 - loss: 1.4676\n",
      "Epoch 27/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6422 - loss: 1.4559\n",
      "Epoch 28/40\n",
      "1241/1241 - 11s - 9ms/step - accuracy: 0.6441 - loss: 1.4471\n",
      "Epoch 29/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6468 - loss: 1.4327\n",
      "Epoch 30/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6490 - loss: 1.4253\n",
      "Epoch 31/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6513 - loss: 1.4141\n",
      "Epoch 32/40\n",
      "1241/1241 - 8s - 6ms/step - accuracy: 0.6516 - loss: 1.4056\n",
      "Epoch 33/40\n",
      "1241/1241 - 8s - 7ms/step - accuracy: 0.6539 - loss: 1.3971\n",
      "Epoch 34/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6555 - loss: 1.3867\n",
      "Epoch 35/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6551 - loss: 1.3768\n",
      "Epoch 36/40\n",
      "1241/1241 - 8s - 6ms/step - accuracy: 0.6589 - loss: 1.3724\n",
      "Epoch 37/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6589 - loss: 1.3614\n",
      "Epoch 38/40\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6601 - loss: 1.3555\n",
      "Epoch 39/40\n",
      "1241/1241 - 11s - 9ms/step - accuracy: 0.6603 - loss: 1.3479\n",
      "Epoch 40/40\n",
      "1241/1241 - 8s - 7ms/step - accuracy: 0.6614 - loss: 1.3411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7ca86dad0310>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=40, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 242578,
     "status": "ok",
     "timestamp": 1740463542543,
     "user": {
      "displayName": "Pankaj Mishra",
      "userId": "00940582812025533532"
     },
     "user_tz": -330
    },
    "id": "DSfjfq4nn-3c",
    "outputId": "5bd6c441-dd59-41d9-da94-ce46f19c37c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1241/1241 - 8s - 7ms/step - accuracy: 0.6637 - loss: 1.3334\n",
      "Epoch 2/25\n",
      "1241/1241 - 8s - 6ms/step - accuracy: 0.6650 - loss: 1.3234\n",
      "Epoch 3/25\n",
      "1241/1241 - 11s - 9ms/step - accuracy: 0.6660 - loss: 1.3209\n",
      "Epoch 4/25\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6651 - loss: 1.3143\n",
      "Epoch 5/25\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6671 - loss: 1.3089\n",
      "Epoch 6/25\n",
      "1241/1241 - 8s - 7ms/step - accuracy: 0.6671 - loss: 1.3031\n",
      "Epoch 7/25\n",
      "1241/1241 - 8s - 6ms/step - accuracy: 0.6689 - loss: 1.2971\n",
      "Epoch 8/25\n",
      "1241/1241 - 8s - 7ms/step - accuracy: 0.6691 - loss: 1.2895\n",
      "Epoch 9/25\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6694 - loss: 1.2877\n",
      "Epoch 10/25\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6701 - loss: 1.2807\n",
      "Epoch 11/25\n",
      "1241/1241 - 8s - 6ms/step - accuracy: 0.6703 - loss: 1.2744\n",
      "Epoch 12/25\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6725 - loss: 1.2702\n",
      "Epoch 13/25\n",
      "1241/1241 - 11s - 9ms/step - accuracy: 0.6721 - loss: 1.2681\n",
      "Epoch 14/25\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6709 - loss: 1.2642\n",
      "Epoch 15/25\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6710 - loss: 1.2614\n",
      "Epoch 16/25\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6721 - loss: 1.2563\n",
      "Epoch 17/25\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6746 - loss: 1.2510\n",
      "Epoch 18/25\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6743 - loss: 1.2452\n",
      "Epoch 19/25\n",
      "1241/1241 - 8s - 7ms/step - accuracy: 0.6749 - loss: 1.2436\n",
      "Epoch 20/25\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6754 - loss: 1.2402\n",
      "Epoch 21/25\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6744 - loss: 1.2376\n",
      "Epoch 22/25\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6745 - loss: 1.2340\n",
      "Epoch 23/25\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6753 - loss: 1.2291\n",
      "Epoch 24/25\n",
      "1241/1241 - 10s - 8ms/step - accuracy: 0.6770 - loss: 1.2275\n",
      "Epoch 25/25\n",
      "1241/1241 - 8s - 7ms/step - accuracy: 0.6756 - loss: 1.2220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7ca86daee210>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=25, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model and tokenizer for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1740463604114,
     "user": {
      "displayName": "Pankaj Mishra",
      "userId": "00940582812025533532"
     },
     "user_tz": -330
    },
    "id": "xG1NPX06n-6E",
    "outputId": "0687a774-ab7c-4a4f-81ce-b8657e160d67"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('nlp_nxt.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9Z1bOCutwAp"
   },
   "outputs": [],
   "source": [
    "# Save the tokenizer\n",
    "with open('tokenizer.pkl', 'wb') as file:\n",
    "    pickle.dump(tokenizer, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r\"C:\\Users\\PC\\Downloads\\nlp_nxt.h5\"\n",
    "tokenizer_path = r\"C:\\Users\\PC\\Downloads\\tokenizer_nlp_nxt.pkl\"\n",
    "max_sequence_len = 14+ 1  # Use the same max length as during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import pickle\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "def load_and_predict_multiple(model_path, tokenizer_path, input_text, max_sequence_len, num_words=1):\n",
    "    # Load the trained model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Load the tokenizer\n",
    "    with open(tokenizer_path, 'rb') as file:\n",
    "        tokenizer = pickle.load(file)\n",
    "    \n",
    "    # Predict multiple words\n",
    "    for _ in range(num_words):\n",
    "        # Tokenize and pad the input text\n",
    "        token_list = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
    "        \n",
    "        # Predict the next word\n",
    "        predicted = model.predict(token_list, verbose=0)\n",
    "        predicted_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == np.argmax(predicted):\n",
    "                predicted_word = word\n",
    "                break\n",
    "        \n",
    "        # Append the predicted word to the input text\n",
    "        input_text += \" \" + predicted_word\n",
    "    \n",
    "    return input_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: good | Predicted next word: good night\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"good\"\n",
    "next_word = load_and_predict_multiple(model_path, tokenizer_path, input_sentence, max_sequence_len)\n",
    "print(f\"Input: {input_sentence} | Predicted next word: {next_word}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: where have you | Predicted next word: where have you been\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"where have you\"\n",
    "next_word = load_and_predict_multiple(model_path, tokenizer_path, input_sentence, max_sequence_len)\n",
    "print(f\"Input: {input_sentence} | Predicted next word: {next_word}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: who are | Predicted next word: who are you\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"who are\"\n",
    "next_word = load_and_predict_multiple(model_path, tokenizer_path, input_sentence, max_sequence_len)\n",
    "print(f\"Input: {input_sentence} | Predicted next word: {next_word}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: marry | Predicted next word: marry me\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"marry\"\n",
    "next_word = load_and_predict_multiple(model_path, tokenizer_path, input_sentence, max_sequence_len)\n",
    "print(f\"Input: {input_sentence} | Predicted next word: {next_word}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: will you marry | Predicted next word: will you marry me\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"will you marry\"\n",
    "next_word = load_and_predict_multiple(model_path, tokenizer_path, input_sentence, max_sequence_len)\n",
    "print(f\"Input: {input_sentence} | Predicted next word: {next_word}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: i love | Predicted next word: i love you\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"i love\"\n",
    "next_word = load_and_predict_multiple(model_path, tokenizer_path, input_sentence, max_sequence_len)\n",
    "print(f\"Input: {input_sentence} | Predicted next word: {next_word}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: i love you | Predicted next word: i love you too\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"i love you\"\n",
    "next_word = load_and_predict_multiple(model_path, tokenizer_path, input_sentence, max_sequence_len)\n",
    "print(f\"Input: {input_sentence} | Predicted next word: {next_word}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: thank | Predicted next word: thank you\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"thank\"\n",
    "next_word = load_and_predict_multiple(model_path, tokenizer_path, input_sentence, max_sequence_len)\n",
    "print(f\"Input: {input_sentence} | Predicted next word: {next_word}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: i love | Predicted: i love you\n",
      "1.24.3\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import pickle\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "model_path = r\"C:\\Users\\PC\\Desktop\\Projects\\git_uplod_NWP_frnds\\nlp_nxt.h5\"\n",
    "tokenizer_path = r\"C:\\Users\\PC\\Desktop\\Projects\\git_uplod_NWP_frnds\\tokenizer_nlp_nxt.pkl\"\n",
    "\n",
    "def load_and_predict_multiple(model_path, tokenizer_path, input_text, max_sequence_len, num_words=1):\n",
    "    model = load_model(model_path)\n",
    "    with open(tokenizer_path, 'rb') as file:\n",
    "        tokenizer = pickle.load(file)\n",
    "    \n",
    "    for _ in range(num_words):\n",
    "        token_list = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
    "        predicted = model.predict(token_list, verbose=0)\n",
    "        predicted_word = [word for word, index in tokenizer.word_index.items() if index == np.argmax(predicted)][0]\n",
    "        input_text += \" \" + predicted_word\n",
    "    \n",
    "    return input_text\n",
    "\n",
    "# Test it out\n",
    "input_sentence = \"i love\"\n",
    "next_word = load_and_predict_multiple(model_path, tokenizer_path, input_sentence, 15)\n",
    "print(f\"Input: {input_sentence} | Predicted: {next_word}\")\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ requirements.txt created with necessary dependencies.\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "\n",
    "required_packages = [\"numpy\", \"keras\"]\n",
    "\n",
    "# Get versions of the required packages\n",
    "with open(\"requirements.txt\", \"w\") as f:\n",
    "    for package in required_packages:\n",
    "        version = pkg_resources.get_distribution(package).version\n",
    "        f.write(f\"{package}=={version}\\n\")\n",
    "\n",
    "print(\"✅ requirements.txt created with necessary dependencies.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"C:\\\\Users\\\\PC\\\\Desktop\\\\Projects\\\\git_uplod_NWP_frnds\\\\nlp_nxt.h5\", compile=False)\n",
    "model.save(\"C:\\\\Users\\\\PC\\\\Desktop\\\\Projects\\\\git_uplod_NWP_frnds\\\\nlp_nxt_fixed.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNkHBcvynGCkrm/NR8SPATY",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
